---
layout: post
title:  "머신러닝 관련"
date:   2021-04-03
excerpt: "인공지능 개론 수업(5)"
tag:
- jekyll 
- moon
- blog
- about
- theme
#feature: http://i.imgur.com/Ds6S7lJ.png
comments: true
---

# 인공지능개론(5)

### 1. 다층 신경망의 학습 - 이진학습 

### ( Multi-Layer Perceptron-binary classfication)

---

#### 생성 배경 : 단층 신경망의 한계 (Limitation of Single-Layer Perceptron)

- 단일 계층 구현 시 선형 및 이진분류로 XOR 를 구현할 수 없음

<figure>
    <a href="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-1.PNG"><img src="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-1.PNG" width="50" height="30"></a>
</figure>

- 다층으로 구현 시 구현 가능! ( 아래는 2개의 층으로 구현)

<figure>
    <a href="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-2.PNG"><img src="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-2.PNG" width="50" height="30"></a>
</figure>

- 더 많은 층을 늘릴 경우

<figure>
    <a href="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-3.PNG"><img src="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-3.PNG" width="50" height="30"></a>
</figure>



---

#### 다층 신경망의 구조 (Forward Pass)

<figure>
    <a href="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-4.PNG"><img src="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-4.PNG" width="50" height="30"></a>
</figure>

- Hidden layer 구성은 모델 구현하는 사람 마음대로 정할 수 있음
- 층 구조, Weight 등 파라미터를 조정하여 모델 수정

---

#### 다층 신경망의 수식(Forward Pas)

<figure>
    <a href="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-5.PNG"><img src="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-5.PNG" width="50" height="30"></a>
</figure>

- Input Layer : X1,X2
- Hiddle Layer : Single Perceptorn의 Output 이 W가 됨.
- Output Layer : Y
- Python의 Numpy를 활용하여 행렬 계산으로 코드 구현

``` python
def NN(X,W1,W2,W3):
    v1 = np.matmul(W1, X.T)
    v1 = v1.T
    Y1 = Sigmoid(v1)
    
    v2 = np.matmul(W2, Y1.T)
    v2 = v2.T
    Y2 = Sigmoid(v2)
    
    v3 = np.matmul(W3, Y2.T)
    v3 = v3.T
    Y = Sigmoid(v3)
    
    return Y

def Sigmoid(x):
    return np.exp(-np.logaddexp(0, -x))
```

---

#### 다층 신경망 Backward Pass

- 주어진 Data를 통해 정답을 *예측*  하는것이 Forward Pass
- 정답을 통해 *원인* 을 찾는 개념

<figure>
    <a href="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-6.PNG"><img src="{{ site.url }}/assets/img/AI_Class/AI_Theory/5-6.PNG" width="50" height="30"></a>
</figure>

- L(Loss) : 주어진 정답이 나오도록 원인(값)을 찾을 때 기준 값, 즉 L이 0에 가까울수록 정답에 대한 영향도가 큰 것